# Word Embedding Visualization

This project visualizes how a small neural network learns word embeddings.

<img src="videos/gif_no_background.gif" width="600"/>
Here you can see ten words that are randomly initialized in a 2-dimensional space. The model then learns to optimize each word's embedding, so that similar words are grouped closer together. 

<img src="videos/gif_1.gif" width="600"/>
In this visualization, you can additionally see how the model learns to classify words into categories.
(The categories are POS tags in this case.) 

<img src="videos/gif_2.gif" width="600"/>
In this last video you can see that depending on different random initializations other representations and classification boundaries are being learned.

