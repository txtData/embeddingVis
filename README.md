# Word Embedding Visualization

This project visualizes how a small neural network learns word embeddings.

![](videos/gif_no_background.gif)
Here you can see ten words that are randomly initialized in a 2-dimensional space. The model then learns to optimize each word's embedding, so that similar words are grouped closer together. 

![](videos/gif_1.gif)
In this visualization, you can additionally see how the model learns to classify words into categories.
(The categories are POS tags in this case.) 

![](videos/gif_2.gif)
In this last video you can see that depending on different random initializations other representations and classification boundaries are being learned.

